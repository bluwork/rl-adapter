<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChangeListManager">
    <list default="true" id="cf73862d-9617-40e0-a99c-a127708a2e16" name="Default Changelist" comment="">
      <change afterPath="$PROJECT_DIR$/.idea/libraries/Leiningen__com_google_code_gson_gson_2_8_5.xml" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/.idea/libraries/Leiningen__org_bytedeco_javacpp_presets_ale_20170702_5c7dfa5_1_3.xml" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/.idea/libraries/Leiningen__org_deeplearning4j_rl4j_ale_0_9_1.xml" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/.idea/uiDesigner.xml" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/client.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/configs.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/core.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/dqn.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/environment.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/exp_replay.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/nnet.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/q_learning.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/clojure/rl_adapter/trainer.clj" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/java/net/ltslab/ai/Const.java" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/java/net/ltslab/ai/LocalMDP.java" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/src/java/net/ltslab/ai/StepData.java" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/compiler.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/compiler.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/libraries/Leiningen__org_deeplearning4j_rl4j_core_0_9_1.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/libraries/Leiningen__org_deeplearning4j_rl4j_core_0_9_1.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/libraries/Leiningen__org_projectlombok_lombok_1_16_16.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/libraries/Leiningen__org_projectlombok_lombok_1_18_8.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/project.clj" beforeDir="false" afterPath="$PROJECT_DIR$/project.clj" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/rl-adapter.iml" beforeDir="false" afterPath="$PROJECT_DIR$/rl-adapter.iml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/client.clj" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/configs.clj" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/core.clj" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/dqn.clj" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/environment.clj" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/exp_replay.clj" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/nnet.clj" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/q_learning.clj" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/src/rl_adapter/trainer.clj" beforeDir="false" />
    </list>
    <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Clojure Test Namespace" />
        <option value="Clojure Namespace" />
        <option value="Class" />
      </list>
    </option>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
  </component>
  <component name="MacroExpansionManager">
    <option name="directoryName" value="GcjmizaN" />
  </component>
  <component name="ProjectId" id="1Pk4FdMO6TNUoMMGOUg1oR7Cu8K" />
  <component name="ProjectLevelVcsManager" settingsEditedManually="true" />
  <component name="PropertiesComponent">
    <property name="SHARE_PROJECT_CONFIGURATION_FILES" value="true" />
    <property name="cursive.last.file.extension./Users/blu/Desktop/ZavrsniRad/Kod/Clojure/rl-adapter/src" value="clj" />
    <property name="cursive.last.file.extension./Users/blu/Desktop/ZavrsniRad/Kod/Clojure/rl-adapter/test" value="clj" />
    <property name="cursive.last.file.extension./Users/bobanlukic/Desktop/ZavrsniRad/Kod/Clojure/rl-adapter/src" value="clj" />
    <property name="last_directory_selection" value="$PROJECT_DIR$/src/net/ltslab/ai" />
    <property name="last_opened_file_path" value="$PROJECT_DIR$" />
    <property name="project.structure.last.edited" value="Modules" />
    <property name="project.structure.proportion" value="0.15" />
    <property name="project.structure.side.proportion" value="0.2" />
    <property name="settings.editor.selected.configurable" value="preferences.keymap" />
  </component>
  <component name="ReplState" timestamp="1567333017815">{:repl-history {:ide [], :local [{:command &quot;(bit-and 255 0xFF)&quot;, :offset 18, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(bit-and 256 0xFF)&quot;, :offset 18, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(bit-and 257 0xFF)&quot;, :offset 18, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(bit-and 258 0xFF)&quot;, :offset 18, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(bit-and 513 0xFF)&quot;, :offset 18, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(eval a)&quot;, :offset 8, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(type a)&quot;, :offset 8, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(rest a)&quot;, :offset 8, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen [frame]\n  ToArray\n  (toArray [frame] (double-array (map #(/ (bit-and % 0xFF ) 255.0)) frame)))&quot;, :offset 116, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. (byte-array [1 2 3 4]))]\n  (type (.toArray :test-screen)))&quot;, :offset 89, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. (byte-array [1 2 3 4]))]\n  (type (.toArray test-screen)))&quot;, :offset 88, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. (byte-array [1 2 3 4]))]\n  (type (.toArray (:fram test-screen))))&quot;, :offset 96, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. (byte-array [1 2 3 4]))]\n  (type (.toArray (:frame test-screen))))&quot;, :offset 97, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 4])]\n  (type (.toArray (:frame test-screen))))&quot;, :offset 84, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 4])]\n  (first (.toArray (:frame test-screen))))&quot;, :offset 85, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (first (.toArray (:frame test-screen))))&quot;, :offset 87, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (doseq (.toArray (:frame test-screen))))&quot;, :offset 87, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (doto (.toArray (:frame test-screen))))&quot;, :offset 86, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen [frame]\n  ToArray\n  (toArray [] (double-array (map #(/ (bit-and % 0xFF ) 255.0)) frame)))&quot;, :offset 111, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(type GameScreen)&quot;, :offset 17, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(type GameScreen.)&quot;, :offset 18, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (.toArray))&quot;, :offset 58, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (.toArray GameScreen))&quot;, :offset 69, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen [frame]\n  ToArray\n  (toArray [frame] (reduce + frame)))&quot;, :offset 77, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen [frame]\n  ToArray\n  (toArray [_] (reduce + frame)))&quot;, :offset 73, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(type (.toArray GameScreen))&quot;, :offset 28, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(reduce + [1 2 3 515])&quot;, :offset 22, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen [frame]\n  ToArray\n  (toArray [_] (double-array (map #(/ (bit-and % 0xFF ) 255.0)) frame)))&quot;, :offset 112, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (seq (.toArray test-screen)))&quot;, :offset 76, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(map + {1 2 3})&quot;, :offset 15, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen [frame]\n  ToArray\n  (toArray [_] (double-array (apply map #(/ (bit-and % 0xFF ) 255.0)) frame)))&quot;, :offset 118, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (.toArray ))&quot;, :offset 59, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen [frame]\n  ToArray\n  (toArray [_] (double-array (apply #(/ (bit-and % 0xFF ) 255.0) frame))))&quot;, :offset 114, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (.toArray _))&quot;, :offset 60, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (.toArray test-screen))&quot;, :offset 70, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (.toArray (:frame test-screen)))&quot;, :offset 79, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen. [1 2 3 515])]\n  (seq (.toArray (:frame test-screen))))&quot;, :offset 85, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen []\n  ToArray\n  (toArray [frame] (double-array (apply #(/ (bit-and % 0xFF ) 255.0) frame))))&quot;, :offset 113, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defrecord GameScreen []\n  ToArray\n  (toArray [frame] (double-array (map #(/ (bit-and % 0xFF ) 255.0) frame))))&quot;, :offset 111, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen.)]\n   (.toArray test-screen) [1 2 3])&quot;, :offset 67, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen.)]\n   (.toArray test-screen) [1 2 513])&quot;, :offset 69, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen.)]\n   (toArray test-screen) [1 2 513])&quot;, :offset 68, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [test-screen (GameScreen.)]\n   (toArray test-screen) )&quot;, :offset 59, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(ns rl-adapter.trainer\n  (:require [rl-adapter.configs :as confs]\n            [rl-adapter.environment :as mdp])\n  (:import (org.deeplearning4j.rl4j.learning.sync.qlearning.discrete QLearningDiscreteConv)\n           (org.deeplearning4j.rl4j.space ArrayObservationSpace DiscreteSpace)\n           (org.deeplearning4j.rl4j.util DataManager)))&quot;, :offset 338, :ns &quot;rl-adapter.core&quot;} {:command &quot;(defn start\n  []\n  (let [mdp (mdp/-&gt;MDP (ArrayObservationSpace. [84 84 3]) (DiscreteSpace. 3))\n        hp-settings (confs/j-history-processing)\n        ql-settings (confs/j-q-learning)\n        qnet-settings (confs/j-convolutional)\n        data-manager (DataManager.)\n        agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]\n    :set))&quot;, :offset 372, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defn start\n  []\n  (let [mdp (mdp/-&gt;MDP (ArrayObservationSpace. (long-array[84 84 3]))(DiscreteSpace. 3))\n        hp-settings (confs/j-history-processing)\n        ql-settings (confs/j-q-learning)\n        qnet-settings (confs/j-convolutional)\n        data-manager (DataManager.)\n        agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]\n    :set))&quot;, :offset 383, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(let [mdp (mdp/-&gt;MDP (ArrayObservationSpace. (long-array[84 84 3]))(DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]\n      :set)&quot;, :offset 375, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defrecord GameScreen [screen]\n  ToArray\n  (toArray [frame] (double-array (map #(/ (bit-and % 0xFF ) 255.0) frame))))&quot;, :offset 117, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(let [\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)])&quot;, :offset 284, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defn start\n    []\n    (let [ \n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]))&quot;, :offset 309, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(let [ mdp (mdp/-&gt;MDP (ArrayObservationSpace. (long-array[84 84 3]))(DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)])&quot;, :offset 365, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defn start\n    []\n    (let [ mdp (mdp/-&gt;MDP (ArrayObservationSpace. (long-array[84 84 3]))(DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]))&quot;, :offset 389, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defn start\n    []\n    (let [ mdp (mdp/MDP. (ArrayObservationSpace. (long-array[84 84 3]))(DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]))&quot;, :offset 388, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defrecord MDP [observationSpace discreteSpace])&quot;, :offset 48, :ns &quot;rl-adapter.environment&quot;} {:command &quot;(defn start\n    []\n    (let [ mdp (MDP. (ArrayObservationSpace. (long-array [84 84 3])) (DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]))&quot;, :offset 386, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defn start\n    []\n    (let [ mdp (-&gt;MDP (ArrayObservationSpace. (long-array [84 84 3])) (DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]))&quot;, :offset 387, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(ArrayObservationSpace. (long-array [84 84 3]))&quot;, :offset 47, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(DiscreteSpace. 3)&quot;, :offset 18, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(int-array [84 84 3])&quot;, :offset 21, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(ArrayObservationSpace. obs-shape)&quot;, :offset 34, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(let [obs-shape (int-array [84 84 3])\n          mdp (-&gt;MDP (ArrayObservationSpace. obs-shape) (DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)])&quot;, :offset 391, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(let [obs-shape (int-array [84 84 3])\n          mdp (MDP. (ArrayObservationSpace. obs-shape) (DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)])&quot;, :offset 390, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(MDP)&quot;, :offset 5, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(mdp/-&gt;MDP)&quot;, :offset 11, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(mdp/-&gt;MDP 1 2)&quot;, :offset 15, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(mdp/-&gt;MDP  (ArrayObservationSpace. obs-shape) (DiscreteSpace. 3))&quot;, :offset 66, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(mdp/-&gt;MDP  (ArrayObservationSpace. (int-array [1 2 3]) ) (DiscreteSpace. 3))&quot;, :offset 77, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(let [obs-shape (int-array [84 84 3])\n          mdp (mdp/-&gt;MDP  (ArrayObservationSpace. (int-array [1 2 3]) ) (DiscreteSpace. 3))\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)])&quot;, :offset 407, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(ns rl-adapter.iris\n  (:require [jutsu.ai.core :as ai]))&quot;, :offset 56, :ns &quot;rl-adapter.core&quot;} {:command &quot;(defn start\n    []\n    (let [mdp (LocalMDP)\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]))&quot;, :offset 322, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(let [mdp (LocalMDP.)\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)])&quot;, :offset 299, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(ns rl-adapter.trainer\n  (:require [rl-adapter.configs :as confs]\n            [rl-adapter.environment :as mdp])\n  (:import (org.deeplearning4j.rl4j.learning.sync.qlearning.discrete QLearningDiscreteConv)\n           (org.deeplearning4j.rl4j.space ArrayObservationSpace DiscreteSpace)\n           (org.deeplearning4j.rl4j.util DataManager)\n           (net.ltslab.ai LocalMDP)))&quot;, :offset 374, :ns &quot;rl-adapter.core&quot;} {:command &quot;(defn start\n    []\n    (let [mdp (LocalMDP.)\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]))&quot;, :offset 323, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(LocalMDP.)&quot;, :offset 11, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(confs/j-q-learning)&quot;, :offset 20, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(confs/j-convolutional)&quot;, :offset 23, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(DataManager.)&quot;, :offset 14, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)&quot;, :offset 79, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(IHistoryProcessor$Configuration.\n    (:history-length hpc)\n    (:rescaled-width hpc)\n    (:rescaled-height hpc)\n    (:croppingWidth hpc)\n    (:croppingHeight hpc)\n    (:offset-x hpc)\n    (:offset-y hpc)\n    (:skip-frame 4))&quot;, :offset 224, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(ns rl-adapter.configs\n  (:import (org.deeplearning4j.rl4j.learning  IHistoryProcessor$Configuration)\n           (org.deeplearning4j.rl4j.learning.sync.qlearning QLearning$QLConfiguration)\n           (org.deeplearning4j.rl4j.network.dqn DQNFactoryStdConv$Configuration)))&quot;, :offset 271, :ns &quot;rl-adapter.core&quot;} {:command &quot;(def hpc\n  \&quot;Training Memory Configuration\&quot;\n  {:history-length 4\n   :rescaled-width 84\n   :rescaled-height 84\n   :cropping-width 84\n   :cropping-height 84\n   :offset-x 0\n   :offset-y 0\n   :skip-frame 4})&quot;, :offset 202, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(def qnc\n  \&quot;Q Learning Configuration\&quot;\n  {:seed 123\n   :max-epoch-step 10000\n   :max-step 8E4\n   :exp-rep-max-size 1000000\n   :batch-size 32\n   :target-dqn-update-freq 10000\n   :update-start 500\n   :reward-factor 0.1\n   :gamma 0.99\n   :error-clamp 100.00\n   :min-epsilon 0.1\n   :epsilon-nb-step 100000\n   :double-dqn true})&quot;, :offset 322, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(def cnc\n  \&quot;DQN Convolutional Configuration\&quot;\n  {:learning-rate 0.00025\n   :l2 0.000\n   :updater nil\n   :listeners nil})&quot;, :offset 119, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(defn j-convolutional\n  []\n  (DQNFactoryStdConv$Configuration.\n    (:learning-rate cnc)\n    (:l2 cnc)\n    (:updater cnc)\n    (:listeners nil)))&quot;, :offset 143, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(defn j-q-learning\n  []\n  (QLearning$QLConfiguration.\n    (:seed qnc)\n    (:max-epoch-step qnc)\n    (:max-step qnc)\n    (:exp-rep-max-size qnc)\n    (:batch-size qnc)\n    (:target-dqn-update-freq qnc)\n    (:update-start qnc)\n    (:reward-factor qnc)\n    (:gamma qnc)\n    (:error-clamp qnc)\n    (:min-epsilon qnc)\n    (:epsilon-nb-step qnc)\n    (:double-dqn qnc)))&quot;, :offset 362, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(IHistoryProcessor$Configuration\n    (:history-length hpc)\n    (:rescaled-width hpc)\n    (:rescaled-height hpc)\n    (:cropping-width hpc)\n    (:cropping-height hpc)\n    (:offset-x hpc)\n    (:offset-y hpc)\n    (:skip-frame 4))&quot;, :offset 225, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(defn j-history-processing\n  []\n  (IHistoryProcessor$Configuration.\n    (:history-length hpc)\n    (:rescaled-width hpc)\n    (:rescaled-height hpc)\n    (:cropping-width hpc)\n    (:cropping-height hpc)\n    (:offset-x hpc)\n    (:offset-y hpc)\n    (:skip-frame 4)))&quot;, :offset 261, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(IHistoryProcessor$Configuration.\n    (:history-length hpc)\n    (:rescaled-width hpc)\n    (:rescaled-height hpc)\n    (:cropping-width hpc)\n    (:cropping-height hpc)\n    (:offset-x hpc)\n    (:offset-y hpc)\n    (:skip-frame 4))&quot;, :offset 226, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(IHistoryProcessor$Configuration.\n    (:history-length hpc)\n    (:rescaled-width hpc)\n    (:rescaled-height hpc)\n    (:cropping-width hpc)\n    (:cropping-height hpc)\n    (:offset-x hpc)\n    (:offset-y hpc)\n    (:skip-frame hpc))&quot;, :offset 228, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(defn j-history-processing\n  []\n  (IHistoryProcessor$Configuration.\n    (:history-length hpc)\n    (:rescaled-width hpc)\n    (:rescaled-height hpc)\n    (:cropping-width hpc)\n    (:cropping-height hpc)\n    (:offset-x hpc)\n    (:offset-y hpc)\n    (:skip-frame hpc)))&quot;, :offset 263, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(j-history-processing)&quot;, :offset 22, :ns &quot;rl-adapter.configs&quot;} {:command &quot;(confs/j-history-processing)&quot;, :offset 28, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defn env-reset\n  \&quot;Post action to reset environment\&quot;\n  []\n  (-&gt; (reset-link)\n      client/get\n      :body))&quot;, :offset 107, :ns &quot;rl-adapter.client&quot;} {:command &quot;(defn env-step\n  \&quot;Post action to get the state of environment\&quot;\n  [action]\n  (-&gt; action\n      step-action-link\n      client/get\n      :body))&quot;, :offset 140, :ns &quot;rl-adapter.client&quot;} {:command &quot;(let [mdp (LocalMDP.)\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]\n      (.train agent))&quot;, :offset 320, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(ns rl-adapter.trainer\n  (:require [rl-adapter.configs :as confs]\n            [rl-adapter.environment :as mdp])\n  (:import (org.deeplearning4j.rl4j.learning.sync.qlearning.discrete QLearningDiscreteConv)\n           (org.deeplearning4j.rl4j.util DataManager)\n           (net.ltslab.ai LocalMDP)))&quot;, :offset 295, :ns &quot;rl-adapter.core&quot;} {:command &quot;(defn start\n    []\n    (let [mdp (LocalMDP.)\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]\n      (.train agent)))&quot;, :offset 344, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(defn start\n    []\n    (let [mdp (LocalMDP.)\n          hp-settings (confs/j-history-processing)\n          ql-settings (confs/j-q-learning)\n          qnet-settings (confs/j-convolutional)\n          data-manager (DataManager.)\n          agent (QLearningDiscreteConv. mdp qnet-settings hp-settings ql-settings data-manager)]\n     (do\n       (.train agent)\n       (.save (\&quot;breakoutGDX.model\&quot;))\n       (.close mdp))))&quot;, :offset 412, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(start)&quot;, :offset 7, :ns &quot;rl-adapter.trainer&quot;} {:command &quot;(train)&quot;, :offset 7, :ns &quot;rl-adapter.trainer&quot;}], :remote []}}</component>
  <component name="RunDashboard">
    <option name="ruleStates">
      <list>
        <RuleState>
          <option name="name" value="ConfigurationTypeDashboardGroupingRule" />
        </RuleState>
        <RuleState>
          <option name="name" value="StatusDashboardGroupingRule" />
        </RuleState>
      </list>
    </option>
  </component>
  <component name="RunManager" selected="Clojure REPL.REPL for rl-adapter">
    <configuration name="REPL for rl-adapter" type="ClojureREPL" factoryName="Local" activateToolWindowBeforeRun="false" temporary="true">
      <module name="rl-adapter" />
      <setting name="replType" value="NREPL" />
      <setting name="execution" value="LEININGEN" />
      <setting name="jvmArgs" value="" />
      <setting name="parameters" value="" />
      <setting name="workingDir" value="$PROJECT_DIR$" />
      <setting name="profiles" value="" />
      <setting name="aliases" value="" />
      <method v="2" />
    </configuration>
    <configuration default="true" type="ClojureREPL" factoryName="Local" activateToolWindowBeforeRun="false">
      <setting name="replType" value="NREPL" />
      <setting name="execution" value="LEININGEN" />
      <module name="" />
      <setting name="jvmArgs" value="" />
      <setting name="parameters" value="" />
      <setting name="workingDir" value="" />
      <setting name="profiles" value="" />
      <setting name="aliases" value="" />
      <method v="2" />
    </configuration>
    <configuration default="true" type="ClojureREPL" factoryName="Remote" activateToolWindowBeforeRun="false">
      <setting name="host" value="" />
      <setting name="port" value="0" />
      <setting name="replType" value="0" />
      <module name="" />
      <method v="2" />
    </configuration>
    <configuration name="rl-adapter.skynet" type="ClojureScriptRunConfiguration" factoryName="Clojure Script" temporary="true">
      <module name="rl-adapter" />
      <setting name="path" value="$PROJECT_DIR$/src/rl_adapter/skynet.clj" />
      <setting name="namespace" value="" />
      <setting name="execution" value="INTELLIJ" />
      <setting name="profiles" value="" />
      <setting name="aliases" value="" />
      <setting name="vmparams" value="" />
      <setting name="params" value="" />
      <setting name="workDir" value="$PROJECT_DIR$/src/rl_adapter" />
      <method v="2" />
    </configuration>
    <recent_temporary>
      <list>
        <item itemvalue="Clojure REPL.REPL for rl-adapter" />
        <item itemvalue="Clojure Application.rl-adapter.skynet" />
      </list>
    </recent_temporary>
  </component>
  <component name="SvnConfiguration">
    <configuration />
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="cf73862d-9617-40e0-a99c-a127708a2e16" name="Default Changelist" comment="" />
      <created>1566404657787</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1566404657787</updated>
    </task>
    <servers />
  </component>
  <component name="Vcs.Log.Tabs.Properties">
    <option name="TAB_STATES">
      <map>
        <entry key="MAIN">
          <value>
            <State>
              <option name="COLUMN_ORDER" />
            </State>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>